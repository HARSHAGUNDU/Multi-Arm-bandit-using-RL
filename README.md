# Multi-Arm-bandit-using-RL

-Conceptualized and executed an advanced problem-solving paradigm leveraging the multi-arm bandit framework, a quintessential
decision-making challenge with the onus on optimizing cumulative rewards amidst a plethora of choices.
-Innovatively employed cutting-edge reinforcement learning (RL) techniques, striking a deft balance between exploration and exploitation. The
result? Identification of options with superlative average rewards, vital for domains spanning online advertising to clinical trials and
recommendation systems.
-Championed the implementation of seminal RL algorithms tailored for the multi-arm bandit challenge, namely epsilon greedy, UCB (Upper
Confidence Bound), and Thompson sampling.
-Measured the efficacy of these algorithms using the ’Regret’ metric, highlighting the disparity between the cumulative reward of the gold
standard option and the elected option, ensuring objective, quantifiable assessments.
-Battled the vagaries of overfitting, a frequent nemesis in the observed data. This comprehensive exercise honed my skills in algorithm
optimization, ensuring our agents navigated the decision-making realm with sagacity, especially amidst noisy or uncertain rewards.
